{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assumptions of Linear Regression\n",
    "\n",
    "- Linearity\n",
    "    - Relationships between the predictors and the outcome variable should be linear\n",
    "- Homogeneity of variance (homoscedasticity)\n",
    "    - Error variance is constant\n",
    "- Independencee\n",
    "    - The errors associated with one observation are not correlated with the errors of any other observation\n",
    "    \n",
    "    \n",
    "More assumptions:\n",
    "- Normality\n",
    "- Independent predictors\n",
    "- Model specification\n",
    "    - Model should be properly specified (no extraneous predictors)\n",
    "    \n",
    "    \n",
    "#### Linearity\n",
    "- The relationship between the independent and dependent variable must be linear\n",
    "\n",
    "But how do we detect violations of this assumption?\n",
    "\n",
    "Resdiual plot: bivariate plot of the preedicted/fitted value against residuals\n",
    "    - Ideally, predicted value will be a linear function of IVs\n",
    "    - Line should be approximately horizontal at zero\n",
    "    \n",
    "#### Checking homoscedasticity\n",
    "- Another residual plot: there should be no pattern of the size of the residuals against fitted values\n",
    "\n",
    "Correcting for violations against homoscedasticity:\n",
    "- Transform outcome variable using log or square root transformation\n",
    "- Use quantile regression, mixed-effects models\n",
    "\n",
    "Detecting violations of homoscedasticity for ANOVA:\n",
    "- Boxplots, residual plots, Leven's test, Bartlett's test, Fligner-Killeen test\n",
    "\n",
    "What can we do if normality is violated?\n",
    "- Transform the data\n",
    "- Remove outliers\n",
    "- Robust statistics and methods\n",
    "\n",
    "#### Data transformation\n",
    "Left skew\n",
    "- e.g., test scores for an easy test (ceiling effect)\n",
    "    - Many high scores, but a few people bombed it...\n",
    "    - How can we transform the data to remove this left skew?\n",
    "\n",
    "If you have a left-skewed distribution, try these:\n",
    "1. Square ($Y \\rightarrow Y^2$)\n",
    "2. Cube ($Y \\rightarrow Y^3$)\n",
    "3. Quartic (($Y \\rightarrow Y^4$)\n",
    "\n",
    "#### Box-cox transformations\n",
    "$$ y \\mapsto y^\\lambda $$\n",
    "\n",
    "Typically, if $|\\lambda| > 1$, we round to the nearest whole number\n",
    "\n",
    "If $\\lambda = 0$, then $y \\mapsto log(y)$\n",
    "\n",
    "In R, we use the `bcPower` function (box-cox family of power transforms)\n",
    "\n",
    "#### How to evaluate transformation outcomes\n",
    "Need to check data before and after each level of transformation, else we might \"overtransform\" or \"undertransform\" our data\n",
    "\n",
    "Effective transformations:\n",
    "1. Improve normality by reducing skewness and kurtosis\n",
    "2. Reduce variance when possible\n",
    "\n",
    "Data transformation may make model interpretation difficult... some transformations are best for strictly predictive models.\n",
    "\n",
    "#### Outliers, leverage points, influential datapoints\n",
    "- Outlier — a data point drastically different from others.\n",
    "- A data point is influential if its presence/absence has a big impact on the relationship/regression model.\n",
    "\n",
    "#### How do we detect outliers and leverage points?\n",
    "- We cannot simply plot every variable...\n",
    "- We cannot simply plot every pair of variables...\n",
    "- Outliers in high dimensional space can be well hidden\n",
    "\n",
    "Method: MCD algorithm\n",
    "\n",
    "How do we detect influential datapoints?\n",
    "- Use Cook's distance\n",
    "- An aggregated influence measure, showing the effect of the $i$th case on all fitted values.\n",
    "- The higher value is, the more influential the case is.\n",
    "- Rule of thumb: any Cook's distance greater than $\\frac{4}{(n-p-1)}$ is a potential influential datapoint\n",
    "\n",
    "#### Robust methods\n",
    "- Tons of options! Great for analyzing data when dropping outliers loses too much information\n",
    "\n",
    "Two categories of robust methods:\n",
    "- Downweight potential outliers\n",
    "- Alternative distributions\n",
    "\n",
    "#### Independent predictors\n",
    "Two variables are linear combinations of one anotheer.\n",
    "- Large level of multicollinearity can cause these problems:\n",
    "    - Large changes in estimated regression coefficients when a variable is added/deleeted, or when an observation is added/deleted.\n",
    "    - Finding non-significant results for important variables. (Similar to a Type II error)\n",
    "    \n",
    "#### Testing for multicollinearity\n",
    "- VIF (variance inflation factor)\n",
    "    - When predictors are uncorrelated, VIF = 1\n",
    "    - When predictors are correlated, VIF > 1\n",
    "    - Rule of thumb: When VIF > 10, multicollinearity has an influence on parameter estimation.\n",
    "- Calculate with the `vif` R function\n",
    "\n",
    "#### Summary of assumptions\n",
    "- LINEARITY (very important)\n",
    "    - Linearity in terms of regression coefficients—not the IVs themselves (we can fit to a quadratic term without violating)\n",
    "- Homogeneity of variance (fairly important)\n",
    "- INDEPENDENCE (very important)\n",
    "    - The subjects are independent from one another — each case is independent\n",
    "\n",
    "- Normality (fairly important)\n",
    "- Independent predictors (fairly important)\n",
    "\n",
    "#### Takehome message\n",
    "- Regression diagonstics are important\n",
    "- We need to check whether the assumptions are satisfied and whether the analyses are correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
